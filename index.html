<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Pro-HOI: Perceptive Root-guided Humanoid-Object Interaction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Pro-HOI</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Pacifico&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    /* 自定义样式 */
    .publication-title {
      font-family: 'Google Sans', sans-serif;
      /* 改回学术字体更正式，或者保留 'Pacifico' 如果你喜欢手写风 */
    }

    .highlight-pro {
      color: #e63946;
    }

    /* 视频网格样式 */
    .grid-container {
      width: 60vw;
      max-width: 60vw;
      margin-left: calc(50% - 30vw);
      margin-right: calc(50% - 30vw);
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(450px, 1fr));
      /* 自适应列宽 */
      gap: 20px;
      padding: 20px 40px;
    }

    .video-item {
      background: #fff;
      border-radius: 8px;
      overflow: hidden;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
      transition: transform 0.2s;
    }

    .video-item:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
    }

    .video-item video {
      width: 100%;
      display: block;
    }

    .caption {
      padding: 10px;
      font-size: 0.9rem;
      text-align: center;
      color: #4a4a4a;
      font-weight: 500;
    }

    /* Pipeline 图片样式 */
    .pipeline-img {
      width: 100%;
      border-radius: 8px;
      border: 1px solid #eee;
      margin-bottom: 10px;
    }

    /* Hero Video Filter 特效 */
    .hero-bg-video {
      width: 100%;
      height: 100%;
      object-fit: cover;
      /* 核心滤镜设置 */
      filter: blur(0px) brightness(0.7) contrast(1.1);
      opacity: 0.89;
      transform: scale(1.05);
      /* 放大一点防止模糊边缘露白 */
    }
  </style>
</head>

<body>

  <section class="hero is-link is-fullheight video"
    style="overflow: hidden; position:relative; background-color: #000;">

    <div class="hero-video" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 0;">
      <video playsinline autoplay muted loop class="hero-bg-video">
        <source src="./static/videos/teaser.mp4" type="video/mp4">
      </video>
    </div>

    <div class="overlay"
      style="background: rgba(0,0,0,0.2); position: absolute; top:0; left:0; width:100%; height:100%; z-index: 1;">
    </div>

    <!-- <div style="position: absolute; bottom: 20px; right: 20px; color: white; padding: 10px 15px; border-radius: 8px; font-size: 0.8rem; z-index: 10; text-shadow: 1px 1px 2px rgba(0,0,0,0.8); text-align: right;">
      <div><sup>*</sup> Equal contribution</div>
      <div><sup>†</sup>Corresponding Author</div>
    </div> -->

    <div class="hero-head is-hidden-mobile" style="z-index: 10;">
      <header class="navbar">
        <div class="container is-fluid">
          <div class="navbar-menu">
            <div class="navbar-end">
              <a class="navbar-item pl-4 pr-4" href="./static/paper/HOI_RSS.pdf"
                style="text-shadow: 1px 1px 4px rgba(0,0,0,0.8);">
                <span class="icon" style="margin-right:5px;">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>PDF</span>
              </a>
              <a href="#" class="navbar-item pl-4 pr-4" style="text-shadow: 1px 1px 4px rgba(0,0,0,0.8);">
                <span class="icon" style="margin-right:5px;">
                  <i class="fab fa-youtube"></i>
                </span>
                <span>Video</span>
              </a>
              <a href="#" class="navbar-item pl-4 pr-4" style="text-shadow: 1px 1px 4px rgba(0,0,0,0.8);">
                <span class="icon" style="margin-right:5px;">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code (Coming Soon)</span>
              </a>
              <!-- <span class="navbar-item pl-4 pr-4">
                <a href="#" class="button is-inverted is-large" style="opacity: 1;">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </header>
    </div>

    <div class="hero-body" style="z-index: 10;">
      <div class="container is-fluid has-text-centered">
        <h1 class="title is-1 publication-title is-size-1-mobile"
          style="font-size: 5rem; text-shadow: 2px 2px 10px rgba(0,0,0,0.8);">
          <span class="highlight-pro" style="font-size: 120px;">Pro-HOI</span>
        </h1>
        <h2 class="subtitle is-3 publication-title"
          style="font-size: 4rem; text-shadow: 1px 1px 6px rgba(0,0,0,0.8); margin-top: 20px;">
            <span class="highlight-pro">P</span>erceptive <span class="highlight-pro">Ro</span>ot-guided <span class="highlight-pro">H</span>umanoid-<span class="highlight-pro">O</span>bject <span class="highlight-pro">I</span>nteraction
        </h2>

        <div class="is-size-4 publication-authors" style="margin-top: 30px; text-shadow: 1px 1px 2px rgba(0,0,0,0.8);">
          <span class="author-block"><a href="#">Yuhang Lin<sup>1,2</sup></a>,</span>
          <span class="author-block"><a href="#">Jiyuan Shi<sup>1</sup></a>,</span>
          <span class="author-block"><a href="#">Dewei Wang<sup>1,3</sup></a>,</span>
          <span class="author-block"><a href="#">Jipeng Kong<sup>1,4</sup></a>,</span>
          <span class="author-block"><a href="#">Yong Liu<sup>2</sup></a>,</span>
          <span class="author-block"><a href="#">Chenjia Bai<sup>1,†</sup></a>,</span>
          <span class="author-block"><a href="#">Xuelong Li<sup>1,†</sup></a></span><br>
          <div><sup>†</sup>Corresponding Author</div>

        </div>

        <div class="is-size-5 publication-authors"
          style="margin-top: 10px; color: #ddd; text-shadow: 1px 1px 2px rgba(0,0,0,0.8);">
          <span class="author-block"></span>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">

        <div class="column">
          <h2 class="title is-3 has-text-centered">Video</h2>
          <div class="publication-video"
            style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1);">
            <iframe src="./static/videos/main_1.MP4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen
              style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
          </div>
        </div>
  </section>

  <section class="section" style="padding-top: 0rem; margin-top: -30px;">
    <div class="container is-max-desktop">
      <div class="columns is-centered">

        <div class="column">
          <h2 class="title is-3 has-text-centered">Abstract</h2>
          <div class="content has-text-justified">
            <p style="font-size: 1rem; line-height: 1.6;">
              Executing reliable Humanoid-Object Interaction
              (HOI) tasks for humanoid robots is hindered by the lack of
              generalized control interfaces and robust closed-loop perception
              mechanisms. In this work, we introduce Perceptive Root-guided
              Humanoid-Object Interaction, Pro-HOI, a generalizable frame-
              work for robust humanoid loco-manipulation. First, we collect
              box-carrying motions that are suitable for real-world deployment
              and optimize penetration artifacts through a Signed Distance
              Field loss. Second, we propose a novel training framework
              that conditions the policy on a desired root-trajectory while
              utilizing reference motion exclusively as a reward. This design
              not only eliminates the need for intricate reward tuning but
              also establishes root trajectory as a universal interface for
              high-level planners, enabling simultaneous navigation and loco-
              manipulation. Furthermore, to ensure operational reliability, we
              incorporate a persistent object estimation module. By fusing real-
              time detection with Digital Twin, this module allows the robot to
              autonomously detect slippage and trigger re-grasping maneuvers.
              Empirical validation on a Unitree G1 robot demonstrates that
              Pro-HOI significantly outperforms baselines in generalization
              and robustness, achieving reliable long-horizon execution in
              complex real-world scenarios.
            </p>

          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="section" style="background-color: #f5f5f5;">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Method</h2>
      <div class="columns is-centered">
        <div class="column is-full">
          <img src="./static/images/pipeline.png" alt="Pro-HOI Pipeline" class="pipeline-img">
          <div class="content has-text-justified is-size-6">
            <p>
              <strong>Overview of Pro-HOI:</strong> 
              <strong>a) Data Preparation:</strong> We frist collect human motion clips using the mocap system, and augment them with object geometries
              in Blender. Then we use SDF-based optimization to generate physically feasible reference motions. 
              <strong>b) Root-Guided Policy Learning:</strong> The RL policy is
              trained to perform whole-body interaction skills conditioned on the desired root trajectory, while utilizing the reference motion as rewards.
              <strong>c) Real-world Deployment:</strong> We integrate FoundationPose for 6D object pose estimation and FAST-LIO2 [42] for root pose estimation, combined with the Interaction Pose
              Prior and a task specific planner to generate target root trajectories. The full stack executes entirely onboard a Jetson NX with a D435i camera and a Mid-360
              LiDAR, achieving robust sim-to-real transfer.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Real-World Experiments</h2>
      <p class="has-text-centered is-size-5" style="margin-bottom: 30px; color: #666;">
        Deployed on Unitree G1 Humanoid - Onboard Computing
      </p>

      <div class="grid-container">

        <div class="video-item" >
          <video autoplay loop muted playsinline controls src="./static/videos/main_1.mp4"></video>
          <div class="caption"><strong>Long-Horizon Robustness:</strong> Continuous carrying cycles in complex scenes.
          </div>
        </div>

        <div class="video-item">
          <video autoplay loop muted playsinline controls src="./static/videos/run_fail.MP4"></video>
          <div class="caption"><strong>Failure Recovery:</strong> Auto re-grasping after slippage via Digital Twin.
          </div>
        </div>

        <div class="video-item">
          <video autoplay loop muted playsinline controls src="./static/videos/digital_twin.mov"></video>
          <div class="caption"><strong>Digital Twin:</strong> Real-time state estimation & drop detection.</div>
        </div>

        <div class="video-item">
          <video autoplay loop muted playsinline controls src="./static/videos/nav_1.MP4"></video>
          <div class="caption"><strong>Obstacle Avoidance:</strong> Navigating around static obstacles.</div>
        </div>

        <div class="video-item">
          <video autoplay loop muted playsinline controls src="./static/videos/nav_2.MP4"></video>
          <div class="caption"><strong>Guided Navigation:</strong> Following high-level directional commands.</div>
        </div>

        <div class="video-item">
          <video autoplay loop muted playsinline controls src="./static/videos/run_1.MP4"></video>
          <div class="caption"><strong>Stylized Running:</strong> High-speed locomotion with load.</div>
        </div>

        <div class="video-item">
          <video autoplay loop muted playsinline controls src="./static/videos/run_2.MP4"></video>
          <div class="caption"><strong>Dynamic Robustness:</strong> Maintaining balance under heavy disturbance.</div>
        </div>

        <div class="video-item">
          <video autoplay loop muted playsinline controls src="./static/videos/main_2.MP4"></video>
          <div class="caption"><strong>Execution Cycle:</strong> Full pick-carry-place pipeline.</div>
        </div>

      </div>
    </div>
  </section>

  <section class="section" id="BibTeX" style="background-color: #f5f5f5;">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{prohoi2025,
  title={Pro-HOI: Perceptive Root-guided Humanoid-Object Interaction},
  author={Anonymous},
  booktitle={Robotics: Science and Systems},
  year={2025}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <p>
          Page template borrowed from <a href="https://nerfies.github.io/">Nerfies</a>.
        </p>
      </div>
    </div>
  </footer>

</body>

</html>
